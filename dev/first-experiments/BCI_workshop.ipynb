{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BCI_workshop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVYVljCVt1Gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCRiHqs9tzON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "583a9b00-9bcc-4a4d-92d6-15064f35b8aa"
      },
      "source": [
        "cd /content/drive/My\\ Drive/Datasets/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLphIBRxT9gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import gettempdir\n",
        "from subprocess import call\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.signal import butter, lfilter, lfilter_zi\n",
        "\n",
        "\n",
        "NOTCH_B, NOTCH_A = butter(4, np.array([55, 65])/(256/2), btype='bandstop')\n",
        "\n",
        "\n",
        "def plot_multichannel(data, params=None):\n",
        "    \"\"\"Create a plot to present multichannel data.\n",
        "    Args:\n",
        "        data (numpy.ndarray):  Multichannel Data [n_samples, n_channels]\n",
        "        params (dict): information about the data acquisition device\n",
        "    TODO Receive labels as arguments\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    n_samples = data.shape[0]\n",
        "    n_channels = data.shape[1]\n",
        "\n",
        "    if params is not None:\n",
        "        fs = params['sampling frequency']\n",
        "        names = params['names of channels']\n",
        "    else:\n",
        "        fs = 1\n",
        "        names = [''] * n_channels\n",
        "\n",
        "    time_vec = np.arange(n_samples) / float(fs)\n",
        "\n",
        "    data = np.fliplr(data)\n",
        "    offset = 0\n",
        "    for i_channel in range(n_channels):\n",
        "        data_ac = data[:, i_channel] - np.mean(data[:, i_channel])\n",
        "        offset = offset + 2 * np.max(np.abs(data_ac))\n",
        "        ax.plot(time_vec, data_ac + offset, label=names[i_channel])\n",
        "\n",
        "    ax.set_xlabel('Time [s]')\n",
        "    ax.set_ylabel('Amplitude')\n",
        "    plt.legend()\n",
        "    plt.draw()\n",
        "\n",
        "\n",
        "def epoch(data, samples_epoch, samples_overlap=0):\n",
        "    \"\"\"Extract epochs from a time series.\n",
        "    Given a 2D array of the shape [n_samples, n_channels]\n",
        "    Creates a 3D array of the shape [wlength_samples, n_channels, n_epochs]\n",
        "    Args:\n",
        "        data (numpy.ndarray or list of lists): data [n_samples, n_channels]\n",
        "        samples_epoch (int): window length in samples\n",
        "        samples_overlap (int): Overlap between windows in samples\n",
        "    Returns:\n",
        "        (numpy.ndarray): epoched data of shape\n",
        "    \"\"\"\n",
        "\n",
        "    if isinstance(data, list):\n",
        "        data = np.array(data)\n",
        "\n",
        "    n_samples, n_channels = data.shape\n",
        "\n",
        "    samples_shift = samples_epoch - samples_overlap\n",
        "\n",
        "    n_epochs =  int(np.floor((n_samples - samples_epoch) / float(samples_shift)) + 1)\n",
        "\n",
        "    # Markers indicate where the epoch starts, and the epoch contains samples_epoch rows\n",
        "    markers = np.asarray(range(0, n_epochs + 1)) * samples_shift\n",
        "    markers = markers.astype(int)\n",
        "\n",
        "    # Divide data in epochs\n",
        "    epochs = np.zeros((samples_epoch, n_channels, n_epochs))\n",
        "\n",
        "    for i in range(0, n_epochs):\n",
        "        epochs[:, :, i] = data[markers[i]:markers[i] + samples_epoch, :]\n",
        "\n",
        "    return epochs\n",
        "\n",
        "\n",
        "def compute_feature_vector(eegdata, fs):\n",
        "    \"\"\"Extract the features from the EEG.\n",
        "    Args:\n",
        "        eegdata (numpy.ndarray): array of dimension [number of samples,\n",
        "                number of channels]\n",
        "        fs (float): sampling frequency of eegdata\n",
        "    Returns:\n",
        "        (numpy.ndarray): feature matrix of shape [number of feature points,\n",
        "            number of different features]\n",
        "    \"\"\"\n",
        "    # 1. Compute the PSD\n",
        "    winSampleLength, nbCh = eegdata.shape\n",
        "\n",
        "    # Apply Hamming window\n",
        "    w = np.hamming(winSampleLength)\n",
        "    dataWinCentered = eegdata - np.mean(eegdata, axis=0)  # Remove offset\n",
        "    dataWinCenteredHam = (dataWinCentered.T*w).T\n",
        "\n",
        "    NFFT = nextpow2(winSampleLength)\n",
        "    Y = np.fft.fft(dataWinCenteredHam, n=NFFT, axis=0)/winSampleLength\n",
        "    PSD = 2*np.abs(Y[0:int(NFFT/2), :])\n",
        "    f = fs/2*np.linspace(0, 1, int(NFFT/2))\n",
        "\n",
        "    # SPECTRAL FEATURES\n",
        "    # Average of band powers\n",
        "    # Delta <4\n",
        "    ind_delta, = np.where(f < 4)\n",
        "    meanDelta = np.mean(PSD[ind_delta, :], axis=0)\n",
        "    # Theta 4-8\n",
        "    ind_theta, = np.where((f >= 4) & (f <= 8))\n",
        "    meanTheta = np.mean(PSD[ind_theta, :], axis=0)\n",
        "    # Alpha 8-12\n",
        "    ind_alpha, = np.where((f >= 8) & (f <= 12))\n",
        "    meanAlpha = np.mean(PSD[ind_alpha, :], axis=0)\n",
        "    # Beta 12-30\n",
        "    ind_beta, = np.where((f >= 12) & (f < 30))\n",
        "    meanBeta = np.mean(PSD[ind_beta, :], axis=0)\n",
        "\n",
        "    feature_vector = np.concatenate((meanDelta, meanTheta, meanAlpha,\n",
        "                                     meanBeta), axis=0)\n",
        "\n",
        "    feature_vector = np.log10(feature_vector)\n",
        "\n",
        "    return feature_vector\n",
        "\n",
        "\n",
        "def nextpow2(i):\n",
        "    \"\"\"\n",
        "    Find the next power of 2 for number i\n",
        "    \"\"\"\n",
        "    n = 1\n",
        "    while n < i:\n",
        "        n *= 2\n",
        "    return n\n",
        "\n",
        "\n",
        "def compute_feature_matrix(epochs, fs):\n",
        "    \"\"\"\n",
        "    Call compute_feature_vector for each EEG epoch\n",
        "    \"\"\"\n",
        "    n_epochs = epochs.shape[2]\n",
        "\n",
        "    for i_epoch in range(n_epochs):\n",
        "        if i_epoch == 0:\n",
        "            feat = compute_feature_vector(epochs[:, :, i_epoch], fs).T\n",
        "            feature_matrix = np.zeros((n_epochs, feat.shape[0])) # Initialize feature_matrix\n",
        "\n",
        "        feature_matrix[i_epoch, :] = compute_feature_vector(\n",
        "                epochs[:, :, i_epoch], fs).T\n",
        "\n",
        "    return feature_matrix\n",
        "\n",
        "\n",
        "def train_classifier(feature_matrix_0, feature_matrix_1, algorithm='SVM'):\n",
        "    \"\"\"Train a binary classifier.\n",
        "    Train a binary classifier. First perform Z-score normalization, then\n",
        "    fit\n",
        "    Args:\n",
        "        feature_matrix_0 (numpy.ndarray): array of shape (n_samples,\n",
        "            n_features) with examples for Class 0\n",
        "        feature_matrix_0 (numpy.ndarray): array of shape (n_samples,\n",
        "            n_features) with examples for Class 1\n",
        "        alg (str): Type of classifer to use. Currently only SVM is\n",
        "            supported.\n",
        "    Returns:\n",
        "        (sklearn object): trained classifier (scikit object)\n",
        "        (numpy.ndarray): normalization mean\n",
        "        (numpy.ndarray): normalization standard deviation\n",
        "    \"\"\"\n",
        "    # Create vector Y (class labels)\n",
        "    class0 = np.zeros((feature_matrix_0.shape[0], 1))\n",
        "    class1 = np.ones((feature_matrix_1.shape[0], 1))\n",
        "\n",
        "    # Concatenate feature matrices and their respective labels\n",
        "    y = np.concatenate((class0, class1), axis=0)\n",
        "    features_all = np.concatenate((feature_matrix_0, feature_matrix_1),\n",
        "                                  axis=0)\n",
        "\n",
        "    # Normalize features columnwise\n",
        "    mu_ft = np.mean(features_all, axis=0)\n",
        "    std_ft = np.std(features_all, axis=0)\n",
        "\n",
        "    X = (features_all - mu_ft) / std_ft\n",
        "\n",
        "    # Train SVM using default parameters\n",
        "    clf = svm.SVC()\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    pipeline_svm = Pipeline(steps=[(\"estandariz\", StandardScaler()),\n",
        "                                  (\"eseuveeme\", clf)\n",
        "                                  ])\n",
        "    grid_hiperparam_svm = {#\"estandariz__with_mean\": [True],\n",
        "                          #\"estandariz__with_std\": [True],\n",
        "                          #\"eseuveeme__C\": [0.96], #np.arange(0.01, 10, 0.05),\n",
        "                          #\"eseuveeme__gamma\": [0.005] #np.arange(0.001, 0.1, 0.001)\n",
        "                          }\n",
        "\n",
        "    grid_search_SVM = GridSearchCV(estimator=pipeline_svm,\n",
        "                                  param_grid=grid_hiperparam_svm,\n",
        "                                  cv=10,\n",
        "                                  scoring=\"accuracy\",\n",
        "                                  verbose=3,\n",
        "                                  n_jobs=-1)\n",
        "    \n",
        "    grid_search_SVM.fit(X, y)\n",
        "\n",
        "    best_params = grid_search_SVM.best_params_\n",
        "    best_cv_score = grid_search_SVM.best_score_\n",
        "\n",
        "    clf = grid_search_SVM.best_estimator_\n",
        "\n",
        "    score = clf.score(X, y.ravel())\n",
        "\n",
        "    # Visualize decision boundary\n",
        "#    plot_classifier_training(clf, X, y, features_to_plot=[0, 1])\n",
        "\n",
        "    return clf, mu_ft, std_ft, score, best_params, best_cv_score\n",
        "\n",
        "\n",
        "def test_classifier(clf, feature_vector, mu_ft, std_ft):\n",
        "    \"\"\"Test the classifier on new data points.\n",
        "    Args:\n",
        "        clf (sklearn object): trained classifier\n",
        "        feature_vector (numpy.ndarray): array of shape (n_samples,\n",
        "            n_features)\n",
        "        mu_ft (numpy.ndarray): normalization mean\n",
        "        std_ft (numpy.ndarray): normalization standard deviation\n",
        "    Returns:\n",
        "        (numpy.ndarray): decision of the classifier on the data points\n",
        "    \"\"\"\n",
        "\n",
        "    # Normalize feature_vector\n",
        "    x = (feature_vector - mu_ft) / std_ft\n",
        "    y_hat = clf.predict(x)\n",
        "\n",
        "    return y_hat\n",
        "\n",
        "\n",
        "def beep(waveform=(79, 45, 32, 50, 99, 113, 126, 127)):\n",
        "    \"\"\"Play a beep sound.\n",
        "    Cross-platform sound playing with standard library only, no sound\n",
        "    file required.\n",
        "    From https://gist.github.com/juancarlospaco/c295f6965ed056dd08da\n",
        "    \"\"\"\n",
        "    wavefile = os.path.join(gettempdir(), \"beep.wav\")\n",
        "    if not os.path.isfile(wavefile) or not os.access(wavefile, os.R_OK):\n",
        "        with open(wavefile, \"w+\") as wave_file:\n",
        "            for sample in range(0, 300, 1):\n",
        "                for wav in range(0, 8, 1):\n",
        "                    wave_file.write(chr(waveform[wav]))\n",
        "    if sys.platform.startswith(\"linux\"):\n",
        "        return call(\"chrt -i 0 aplay '{fyle}'\".format(fyle=wavefile),\n",
        "                    shell=1)\n",
        "    if sys.platform.startswith(\"darwin\"):\n",
        "        return call(\"afplay '{fyle}'\".format(fyle=wavefile), shell=True)\n",
        "    if sys.platform.startswith(\"win\"):  # FIXME: This is Ugly.\n",
        "        return call(\"start /low /min '{fyle}'\".format(fyle=wavefile),\n",
        "                    shell=1)\n",
        "\n",
        "\n",
        "def get_feature_names(ch_names):\n",
        "    \"\"\"Generate the name of the features.\n",
        "    Args:\n",
        "        ch_names (list): electrode names\n",
        "    Returns:\n",
        "        (list): feature names\n",
        "    \"\"\"\n",
        "    bands = ['delta', 'theta', 'alpha', 'beta']\n",
        "\n",
        "    feat_names = []\n",
        "    for band in bands:\n",
        "        for ch in range(len(ch_names)):\n",
        "            feat_names.append(band + '-' + ch_names[ch])\n",
        "\n",
        "    return feat_names\n",
        "\n",
        "\n",
        "def update_buffer(data_buffer, new_data, notch=False, filter_state=None):\n",
        "    \"\"\"\n",
        "    Concatenates \"new_data\" into \"data_buffer\", and returns an array with\n",
        "    the same size as \"data_buffer\"\n",
        "    \"\"\"\n",
        "    if new_data.ndim == 1:\n",
        "        new_data = new_data.reshape(-1, data_buffer.shape[1])\n",
        "\n",
        "    if notch:\n",
        "        if filter_state is None:\n",
        "            filter_state = np.tile(lfilter_zi(NOTCH_B, NOTCH_A),\n",
        "                                   (data_buffer.shape[1], 1)).T\n",
        "        new_data, filter_state = lfilter(NOTCH_B, NOTCH_A, new_data, axis=0,\n",
        "                                         zi=filter_state)\n",
        "\n",
        "    new_buffer = np.concatenate((data_buffer, new_data), axis=0)\n",
        "    new_buffer = new_buffer[new_data.shape[0]:, :]\n",
        "\n",
        "    return new_buffer, filter_state\n",
        "\n",
        "\n",
        "def get_last_data(data_buffer, newest_samples):\n",
        "    \"\"\"\n",
        "    Obtains from \"buffer_array\" the \"newest samples\" (N rows from the\n",
        "    bottom of the buffer)\n",
        "    \"\"\"\n",
        "    new_buffer = data_buffer[(data_buffer.shape[0] - newest_samples):, :]\n",
        "\n",
        "    return new_buffer\n",
        "\n",
        "\n",
        "class DataPlotter():\n",
        "    \"\"\"\n",
        "    Class for creating and updating a line plot.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nbPoints, chNames, fs=None, title=None):\n",
        "        \"\"\"Initialize the figure.\"\"\"\n",
        "\n",
        "        self.nbPoints = nbPoints\n",
        "        self.chNames = chNames\n",
        "        self.nbCh = len(self.chNames)\n",
        "\n",
        "        self.fs = 1 if fs is None else fs\n",
        "        self.figTitle = '' if title is None else title\n",
        "\n",
        "        data = np.empty((self.nbPoints, 1))*np.nan\n",
        "        self.t = np.arange(data.shape[0])/float(self.fs)\n",
        "\n",
        "        # Create offset parameters for plotting multiple signals\n",
        "        self.yAxisRange = 100\n",
        "        self.chRange = self.yAxisRange/float(self.nbCh)\n",
        "        self.offsets = np.round((np.arange(self.nbCh)+0.5)*(self.chRange))\n",
        "\n",
        "        # Create the figure and axis\n",
        "        plt.ion()\n",
        "        self.fig, self.ax = plt.subplots()\n",
        "        self.ax.set_yticks(self.offsets)\n",
        "        self.ax.set_yticklabels(self.chNames)\n",
        "\n",
        "        # Initialize the figure\n",
        "        self.ax.set_title(self.figTitle)\n",
        "\n",
        "        self.chLinesDict = {}\n",
        "        for i, chName in enumerate(self.chNames):\n",
        "            self.chLinesDict[chName], = self.ax.plot(\n",
        "                    self.t, data+self.offsets[i], label=chName)\n",
        "\n",
        "        self.ax.set_xlabel('Time')\n",
        "        self.ax.set_ylim([0, self.yAxisRange])\n",
        "        self.ax.set_xlim([np.min(self.t), np.max(self.t)])\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    def update_plot(self, data):\n",
        "        \"\"\" Update the plot \"\"\"\n",
        "\n",
        "        data = data - np.mean(data, axis=0)\n",
        "        std_data = np.std(data, axis=0)\n",
        "        std_data[np.where(std_data == 0)] = 1\n",
        "        data = data/std_data*self.chRange/5.0\n",
        "\n",
        "        for i, chName in enumerate(self.chNames):\n",
        "            self.chLinesDict[chName].set_ydata(data[:, i] + self.offsets[i])\n",
        "\n",
        "        self.fig.canvas.draw()\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\" Clear the figure \"\"\"\n",
        "\n",
        "        blankData = np.empty((self.nbPoints, 1))*np.nan\n",
        "\n",
        "        for i, chName in enumerate(self.chNames):\n",
        "            self.chLinesDict[chName].set_ydata(blankData)\n",
        "\n",
        "        self.fig.canvas.draw()\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\" Close the figure \"\"\"\n",
        "\n",
        "        plt.close(self.fig)\n",
        "\n",
        "\n",
        "def plot_classifier_training(clf, X, y, features_to_plot=[0, 1]):\n",
        "    \"\"\"Visualize the decision boundary of a classifier.\n",
        "    Args:\n",
        "        clf (sklearn object): trained classifier\n",
        "        X (numpy.ndarray): data to visualize the decision boundary for\n",
        "        y (numpy.ndarray): labels for X\n",
        "    Keyword Args:\n",
        "        features_to_plot (list): indices of the two features to use for\n",
        "            plotting\n",
        "    Inspired from: http://scikit-learn.org/stable/auto_examples/tree/plot_iris.html\n",
        "    \"\"\"\n",
        "\n",
        "    plot_colors = \"bry\"\n",
        "    plot_step = 0.02\n",
        "    n_classes = len(np.unique(y))\n",
        "\n",
        "    x_min = np.min(X[:, 1])-1\n",
        "    x_max = np.max(X[:, 1])+1\n",
        "    y_min = np.min(X[:, 0])-1\n",
        "    y_max = np.max(X[:, 0])+1\n",
        "\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
        "                         np.arange(y_min, y_max, plot_step))\n",
        "\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.5)\n",
        "\n",
        "    # Plot the training points\n",
        "    for i, color in zip(range(n_classes), plot_colors):\n",
        "        idx = np.where(y == i)\n",
        "        ax.scatter(X[idx, 0], X[idx, 1], c=color, cmap=plt.cm.Paired)\n",
        "\n",
        "    plt.axis('tight')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E99erwQfVAjw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "cb93cbf4-2e22-4133-b28d-c638243418c4"
      },
      "source": [
        "    # 16 canales\n",
        "    \n",
        "    \"\"\" 2. SET EXPERIMENTAL PARAMETERS \"\"\"\n",
        "\n",
        "    # Length of the EEG data buffer (in seconds)\n",
        "    # This buffer will hold last n seconds of data and be used for calculations\n",
        "    buffer_length = 7\n",
        "\n",
        "    # Length of the epochs used to compute the FFT (in seconds)\n",
        "    epoch_length = 5\n",
        "\n",
        "    # Amount of overlap between two consecutive epochs (in seconds)\n",
        "    overlap_length = 0.0\n",
        "\n",
        "    # Amount to 'shift' the start of each next consecutive epoch\n",
        "    shift_length = epoch_length - overlap_length\n",
        "\n",
        "    # Index of the channel (electrode) to be used\n",
        "    # 0 = left ear, 1 = left forehead, 2 = right forehead, 3 = right ear\n",
        "    ##index_channel = args.channels\n",
        "    # Name of our channel for plotting purposes\n",
        "    \n",
        "    ch_names = ['Channel_'+str(i) for i in range(1,17)]\n",
        "    n_channels = len(ch_names)\n",
        "\n",
        "    # Get names of features\n",
        "    # ex. ['delta - CH1', 'pwr-theta - CH1', 'pwr-alpha - CH1',...]\n",
        "    feature_names = get_feature_names(ch_names)\n",
        "\n",
        "    # Number of seconds to collect training data for (one class)\n",
        "    training_length = 10\n",
        "    fs = 256\n",
        "\n",
        "    dir = './dataframes/16_channels'\n",
        "    files = sorted([dir+'/'+f for f in os.listdir(dir)])\n",
        "\n",
        "    eeg_data0 = np.zeros((46080,16))\n",
        "    eeg_data1 = np.zeros((46080,16))\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for f in files:\n",
        "      array_f = np.load(f)\n",
        "      array_f_0 = array_f[0:2560,:]\n",
        "      array_f_1 = array_f[2560:5120,:]\n",
        "      eeg_data0[2560*counter:2560*(counter+1),:] = array_f_0\n",
        "      eeg_data1[2560*counter:2560*(counter+1),:] = array_f_1\n",
        "\n",
        "      assert len(eeg_data0) == len(eeg_data1)\n",
        "\n",
        "      counter +=1\n",
        " \n",
        "    # Divide data into epochs\n",
        "    eeg_epochs0 = epoch(eeg_data0, epoch_length * fs,\n",
        "                            overlap_length * fs)\n",
        "    eeg_epochs1 = epoch(eeg_data1, epoch_length * fs,\n",
        "                            overlap_length * fs)\n",
        "    \n",
        "    \"\"\" 4. COMPUTE FEATURES AND TRAIN CLASSIFIER \"\"\"\n",
        "\n",
        "    feat_matrix0 = compute_feature_matrix(eeg_epochs0, fs)\n",
        "    feat_matrix1 = compute_feature_matrix(eeg_epochs1, fs)\n",
        "\n",
        "    [classifier, mu_ft, std_ft, score, best_params, best_cv_score] = train_classifier(\n",
        "            feat_matrix0, feat_matrix1, 'SVM')\n",
        "\n",
        "    \n",
        "    print('Mejores parámetros: ', best_params)\n",
        "    print('Mejor score en CV: ', best_cv_score)\n",
        "    \n",
        "    print(str(score * 100) + '% correctly predicted')\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mejores parámetros:  {}\n",
            "Mejor score en CV:  0.5138888888888888\n",
            "91.66666666666666% correctly predicted\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.2s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4KRWgahY4DR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a54231f0-9a48-4ee7-cc61-2aa43697c47b"
      },
      "source": [
        "# 14 canales (sin los de atrás)\n",
        "    \n",
        "    \"\"\" 2. SET EXPERIMENTAL PARAMETERS \"\"\"\n",
        "\n",
        "    # Length of the EEG data buffer (in seconds)\n",
        "    # This buffer will hold last n seconds of data and be used for calculations\n",
        "    buffer_length = 7\n",
        "\n",
        "    # Length of the epochs used to compute the FFT (in seconds)\n",
        "    epoch_length = 5\n",
        "\n",
        "    # Amount of overlap between two consecutive epochs (in seconds)\n",
        "    overlap_length = 0.0\n",
        "\n",
        "    # Amount to 'shift' the start of each next consecutive epoch\n",
        "    shift_length = epoch_length - overlap_length\n",
        "\n",
        "    # Index of the channel (electrode) to be used\n",
        "    # 0 = left ear, 1 = left forehead, 2 = right forehead, 3 = right ear\n",
        "    ##index_channel = args.channels\n",
        "    # Name of our channel for plotting purposes\n",
        "    \n",
        "    ch_names = ['Channel_'+str(i) for i in range(1,15)]\n",
        "    n_channels = len(ch_names)\n",
        "\n",
        "    # Get names of features\n",
        "    # ex. ['delta - CH1', 'pwr-theta - CH1', 'pwr-alpha - CH1',...]\n",
        "    feature_names = get_feature_names(ch_names)\n",
        "\n",
        "    # Number of seconds to collect training data for (one class)\n",
        "    training_length = 10\n",
        "    fs = 256\n",
        "\n",
        "    dir = './dataframes/16_channels'\n",
        "    files = sorted([dir+'/'+f for f in os.listdir(dir)])\n",
        "\n",
        "    eeg_data0 = np.zeros((46080,14))\n",
        "    eeg_data1 = np.zeros((46080,14))\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for f in files:\n",
        "      array_f = np.load(f)\n",
        "      array_f_0 = array_f[0:2560,:]\n",
        "      array_f_1 = array_f[2560:5120,:]\n",
        "\n",
        "      array_f_0 = array_f_0[:,:14]\n",
        "      array_f_1 = array_f_1[:,:14]\n",
        "\n",
        "      eeg_data0[2560*counter:2560*(counter+1),:] = array_f_0\n",
        "      eeg_data1[2560*counter:2560*(counter+1),:] = array_f_1\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "      assert len(eeg_data0) == len(eeg_data1)\n",
        "\n",
        "      counter +=1\n",
        " \n",
        "    # Divide data into epochs\n",
        "    eeg_epochs0 = epoch(eeg_data0, epoch_length * fs,\n",
        "                            overlap_length * fs)\n",
        "    eeg_epochs1 = epoch(eeg_data1, epoch_length * fs,\n",
        "                            overlap_length * fs)\n",
        "    \n",
        "    \"\"\" 4. COMPUTE FEATURES AND TRAIN CLASSIFIER \"\"\"\n",
        "\n",
        "    feat_matrix0 = compute_feature_matrix(eeg_epochs0, fs)\n",
        "    feat_matrix1 = compute_feature_matrix(eeg_epochs1, fs)\n",
        "\n",
        "    [classifier, mu_ft, std_ft, score] = train_classifier(\n",
        "            feat_matrix0, feat_matrix1, 'SVM')\n",
        "\n",
        "    print(str(score * 100) + '% correctly predicted')\n",
        "\n",
        "\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.2s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-bb0ba3346ef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m [classifier, mu_ft, std_ft, score] = train_classifier(\n\u001b[0;32m---> 71\u001b[0;31m         feat_matrix0, feat_matrix1, 'SVM')\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'% correctly predicted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3stK1UGSj-o_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "102a701c-b2f6-4b6a-b615-2a31e761be09"
      },
      "source": [
        "# 12 canales (sin los de alante)\n",
        "    \n",
        "    \"\"\" 2. SET EXPERIMENTAL PARAMETERS \"\"\"\n",
        "\n",
        "    # Length of the EEG data buffer (in seconds)\n",
        "    # This buffer will hold last n seconds of data and be used for calculations\n",
        "    buffer_length = 7\n",
        "\n",
        "    # Length of the epochs used to compute the FFT (in seconds)\n",
        "    epoch_length = 5\n",
        "\n",
        "    # Amount of overlap between two consecutive epochs (in seconds)\n",
        "    overlap_length = 0.0\n",
        "\n",
        "    # Amount to 'shift' the start of each next consecutive epoch\n",
        "    shift_length = epoch_length - overlap_length\n",
        "\n",
        "    # Index of the channel (electrode) to be used\n",
        "    # 0 = left ear, 1 = left forehead, 2 = right forehead, 3 = right ear\n",
        "    ##index_channel = args.channels\n",
        "    # Name of our channel for plotting purposes\n",
        "    \n",
        "    ch_names = ['Channel_'+str(i) for i in range(4,17)]\n",
        "    n_channels = len(ch_names)\n",
        "\n",
        "    # Get names of features\n",
        "    # ex. ['delta - CH1', 'pwr-theta - CH1', 'pwr-alpha - CH1',...]\n",
        "    feature_names = get_feature_names(ch_names)\n",
        "\n",
        "    # Number of seconds to collect training data for (one class)\n",
        "    training_length = 10\n",
        "    fs = 256\n",
        "\n",
        "    dir = './dataframes/16_channels'\n",
        "    files = sorted([dir+'/'+f for f in os.listdir(dir)])\n",
        "\n",
        "    eeg_data0 = np.zeros((46080,12))\n",
        "    eeg_data1 = np.zeros((46080,12))\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for f in files:\n",
        "      array_f = np.load(f)\n",
        "      array_f_0 = array_f[0:2560,:]\n",
        "      array_f_1 = array_f[2560:5120,:]\n",
        "\n",
        "      array_f_0 = array_f_0[:,4:16]\n",
        "      array_f_1 = array_f_1[:,4:16]\n",
        "\n",
        "      eeg_data0[2560*counter:2560*(counter+1),:] = array_f_0\n",
        "      eeg_data1[2560*counter:2560*(counter+1),:] = array_f_1\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "      assert len(eeg_data0) == len(eeg_data1)\n",
        "\n",
        "      counter +=1\n",
        " \n",
        "    # Divide data into epochs\n",
        "    eeg_epochs0 = epoch(eeg_data0, epoch_length * fs,\n",
        "                            overlap_length * fs)\n",
        "    eeg_epochs1 = epoch(eeg_data1, epoch_length * fs,\n",
        "                            overlap_length * fs)\n",
        "    \n",
        "    \"\"\" 4. COMPUTE FEATURES AND TRAIN CLASSIFIER \"\"\"\n",
        "\n",
        "    feat_matrix0 = compute_feature_matrix(eeg_epochs0, fs)\n",
        "    feat_matrix1 = compute_feature_matrix(eeg_epochs1, fs)\n",
        "\n",
        "    [classifier, mu_ft, std_ft, score] = train_classifier(\n",
        "            feat_matrix0, feat_matrix1, 'SVM')\n",
        "\n",
        "    print(str(score * 100) + '% correctly predicted')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.5% correctly predicted\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8Bz7koHokzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "bab0fd08-88b7-4449-82ff-799449afbbda"
      },
      "source": [
        ""
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "83.33333333333334% correctly predicted\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BYMOIx9UUZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "41e0b3fa-dd5d-4147-c15d-766f46a12168"
      },
      "source": [
        "\"\"\"\n",
        "Exercise 2: A basic Brain-Computer Interface\n",
        "=============================================\n",
        "Description:\n",
        "In this second exercise, we will learn how to use an automatic algorithm to\n",
        "recognize somebody's mental states from their EEG. We will use a classifier,\n",
        "i.e., an algorithm that, provided some data, learns to recognize patterns,\n",
        "and can then classify similar unseen information.\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import numpy as np  # Module that simplifies computations on matrices\n",
        "import matplotlib.pyplot as plt  # Module used for plotting\n",
        "from pylsl import StreamInlet, resolve_byprop  # Module to receive EEG data\n",
        "\n",
        "#import bci_workshop_tools as BCIw  # Our own functions for the workshop\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    \"\"\" 0. PARSE ARGUMENTS \"\"\"\n",
        "    parser = argparse.ArgumentParser(description='BCI Workshop example 2')\n",
        "    parser.add_argument('channels', metavar='N', type=int, nargs='*',\n",
        "        default=[0, 1, 2, 3],\n",
        "        help='channel number to use. If not specified, all the channels are used')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    \"\"\" 1. CONNECT TO EEG STREAM \"\"\"\n",
        "\n",
        "    # Search for active LSL stream\n",
        "    print('Looking for an EEG stream...')\n",
        "    streams = resolve_byprop('type', 'EEG', timeout=2)\n",
        "    if len(streams) == 0:\n",
        "        raise RuntimeError('Can\\'t find EEG stream.')\n",
        "\n",
        "    # Set active EEG stream to inlet and apply time correction\n",
        "    print(\"Start acquiring data\")\n",
        "    inlet = StreamInlet(streams[0], max_chunklen=12)\n",
        "    eeg_time_correction = inlet.time_correction()\n",
        "\n",
        "    # Get the stream info, description, sampling frequency, number of channels\n",
        "    info = inlet.info()\n",
        "    description = info.desc()\n",
        "    fs = int(info.nominal_srate())\n",
        "    n_channels = info.channel_count()\n",
        "\n",
        "    # Get names of all channels\n",
        "    ch = description.child('channels').first_child()\n",
        "    ch_names = [ch.child_value('label')]\n",
        "    for i in range(1, n_channels):\n",
        "        ch = ch.next_sibling()\n",
        "        ch_names.append(ch.child_value('label'))\n",
        "\n",
        "    \"\"\" 2. SET EXPERIMENTAL PARAMETERS \"\"\"\n",
        "\n",
        "    # Length of the EEG data buffer (in seconds)\n",
        "    # This buffer will hold last n seconds of data and be used for calculations\n",
        "    buffer_length = 15\n",
        "\n",
        "    # Length of the epochs used to compute the FFT (in seconds)\n",
        "    epoch_length = 1\n",
        "\n",
        "    # Amount of overlap between two consecutive epochs (in seconds)\n",
        "    overlap_length = 0.8\n",
        "\n",
        "    # Amount to 'shift' the start of each next consecutive epoch\n",
        "    shift_length = epoch_length - overlap_length\n",
        "\n",
        "    # Index of the channel (electrode) to be used\n",
        "    # 0 = left ear, 1 = left forehead, 2 = right forehead, 3 = right ear\n",
        "    index_channel = args.channels\n",
        "    # Name of our channel for plotting purposes\n",
        "    ch_names = [ch_names[i] for i in index_channel]\n",
        "    n_channels = len(index_channel)\n",
        "\n",
        "    # Get names of features\n",
        "    # ex. ['delta - CH1', 'pwr-theta - CH1', 'pwr-alpha - CH1',...]\n",
        "    feature_names = BCIw.get_feature_names(ch_names)\n",
        "\n",
        "    # Number of seconds to collect training data for (one class)\n",
        "    training_length = 20\n",
        "\n",
        "    \"\"\" 3. RECORD TRAINING DATA \"\"\"\n",
        "\n",
        "    # Record data for mental activity 0\n",
        "    BCIw.beep()\n",
        "    eeg_data0, timestamps0 = inlet.pull_chunk(\n",
        "            timeout=training_length+1, max_samples=fs * training_length)\n",
        "    eeg_data0 = np.array(eeg_data0)[:, index_channel]\n",
        "\n",
        "    print('\\nClose your eyes!\\n')\n",
        "\n",
        "    # Record data for mental activity 1\n",
        "    BCIw.beep()  # Beep sound\n",
        "    eeg_data1, timestamps1 = inlet.pull_chunk(\n",
        "            timeout=training_length+1, max_samples=fs * training_length)\n",
        "    eeg_data1 = np.array(eeg_data1)[:, index_channel]\n",
        "\n",
        "    # Divide data into epochs\n",
        "    eeg_epochs0 = BCIw.epoch(eeg_data0, epoch_length * fs,\n",
        "                             overlap_length * fs)\n",
        "    eeg_epochs1 = BCIw.epoch(eeg_data1, epoch_length * fs,\n",
        "                             overlap_length * fs)\n",
        "\n",
        "    \"\"\" 4. COMPUTE FEATURES AND TRAIN CLASSIFIER \"\"\"\n",
        "\n",
        "    feat_matrix0 = BCIw.compute_feature_matrix(eeg_epochs0, fs)\n",
        "    feat_matrix1 = BCIw.compute_feature_matrix(eeg_epochs1, fs)\n",
        "\n",
        "    [classifier, mu_ft, std_ft, score] = BCIw.train_classifier(\n",
        "            feat_matrix0, feat_matrix1, 'SVM')\n",
        "\n",
        "    print(str(score * 100) + '% correctly predicted')\n",
        "\n",
        "    BCIw.beep()\n",
        "\n",
        "    \"\"\" 5. USE THE CLASSIFIER IN REAL-TIME\"\"\"\n",
        "\n",
        "    # Initialize the buffers for storing raw EEG and decisions\n",
        "    eeg_buffer = np.zeros((int(fs * buffer_length), n_channels))\n",
        "    filter_state = None  # for use with the notch filter\n",
        "    decision_buffer = np.zeros((30, 1))\n",
        "\n",
        "    plotter_decision = BCIw.DataPlotter(30, ['Decision'])\n",
        "\n",
        "    # The try/except structure allows to quit the while loop by aborting the\n",
        "    # script with <Ctrl-C>\n",
        "    print('Press Ctrl-C in the console to break the while loop.')\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "\n",
        "            \"\"\" 3.1 ACQUIRE DATA \"\"\"\n",
        "            # Obtain EEG data from the LSL stream\n",
        "            eeg_data, timestamp = inlet.pull_chunk(\n",
        "                    timeout=1, max_samples=int(shift_length * fs))\n",
        "\n",
        "            # Only keep the channel we're interested in\n",
        "            ch_data = np.array(eeg_data)[:, index_channel]\n",
        "\n",
        "            # Update EEG buffer\n",
        "            eeg_buffer, filter_state = BCIw.update_buffer(\n",
        "                    eeg_buffer, ch_data, notch=True,\n",
        "                    filter_state=filter_state)\n",
        "\n",
        "            \"\"\" 3.2 COMPUTE FEATURES AND CLASSIFY \"\"\"\n",
        "            # Get newest samples from the buffer\n",
        "            data_epoch = BCIw.get_last_data(eeg_buffer,\n",
        "                                            epoch_length * fs)\n",
        "\n",
        "            # Compute features\n",
        "            feat_vector = BCIw.compute_feature_vector(data_epoch, fs)\n",
        "            y_hat = BCIw.test_classifier(classifier,\n",
        "                                         feat_vector.reshape(1, -1), mu_ft,\n",
        "                                         std_ft)\n",
        "            print(y_hat)\n",
        "\n",
        "            decision_buffer, _ = BCIw.update_buffer(decision_buffer,\n",
        "                                                    np.reshape(y_hat, (-1, 1)))\n",
        "\n",
        "            \"\"\" 3.3 VISUALIZE THE DECISIONS \"\"\"\n",
        "            plotter_decision.update_plot(decision_buffer)\n",
        "            plt.pause(0.00001)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "\n",
        "        print('Closed!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [N [N ...]]\n",
            "ipykernel_launcher.py: error: argument N: invalid int value: '/root/.local/share/jupyter/runtime/kernel-200b0441-5e33-4601-8ab7-befb86fa13d6.json'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yxHlYK_fXUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}